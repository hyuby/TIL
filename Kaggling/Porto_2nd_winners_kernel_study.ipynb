{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import lightgbm as lgbm\nfrom scipy import sparse as ssp\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":112,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Gini(y_true, y_pred):\n    # check and get number of samples\n    assert y_true.shape == y_pred.shape\n    n_samples = y_true.shape[0]\n\n    # sort rows on prediction column\n    # (from largest to smallest)\n    arr = np.array([y_true, y_pred]).transpose()\n    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n\n    # get Lorenz curves\n    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n\n    # get Gini coefficients (area between curves)\n    G_true = np.sum(L_ones - L_true)\n    G_pred = np.sum(L_ones - L_pred)\n\n    # normalize to true Gini coefficient\n    return G_pred * 1. / G_true\n","execution_count":113,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_only = True\nsave_cv = True\nfull_train = False","execution_count":114,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evalerror(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'gini', Gini(labels, preds), True\n","execution_count":115,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/'","execution_count":116,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NROWS = 50000","execution_count":228,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(path + 'train.csv', nrows=NROWS)","execution_count":229,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label = train['target']\ntrain_id = train['id']\ntest = pd.read_csv(path + 'test.csv', nrows=NROWS)\ntest_id = test['id']","execution_count":230,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NFOLDS = 5\nkfold = StratifiedKFold(n_splits = NFOLDS, shuffle=True, random_state=21)","execution_count":231,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['target'].values\ndrop_feature = [\n    'id',\n    'target'\n]","execution_count":232,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= train.drop(drop_feature, axis=1)","execution_count":233,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = X.columns.tolist()\ncat_features = [c for c in feature_names if ('cat' in c and 'cound' not in c)]\nnum_features = [c for c in feature_names if ('cat' not in c and 'calc' in c)]","execution_count":234,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"calc는 도움이 안되기 때문에 다 빼버린다"},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"(train == -1).sum(axis=1)","execution_count":235,"outputs":[{"output_type":"execute_result","execution_count":235,"data":{"text/plain":"0        1\n1        2\n2        3\n3        0\n4        2\n5        1\n6        1\n7        0\n8        1\n9        0\n10       2\n11       2\n12       2\n13       0\n14       2\n15       2\n16       2\n17       0\n18       3\n19       2\n20       2\n21       2\n22       0\n23       2\n24       1\n25       2\n26       1\n27       1\n28       2\n29       1\n        ..\n49970    2\n49971    0\n49972    2\n49973    2\n49974    3\n49975    0\n49976    1\n49977    2\n49978    2\n49979    1\n49980    0\n49981    0\n49982    2\n49983    2\n49984    2\n49985    2\n49986    0\n49987    0\n49988    0\n49989    2\n49990    3\n49991    1\n49992    0\n49993    2\n49994    2\n49995    1\n49996    1\n49997    3\n49998    2\n49999    3\nLength: 50000, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([(train == -1).sum(axis=1),train['target']], axis=1).groupby(0).mean()","execution_count":236,"outputs":[{"output_type":"execute_result","execution_count":236,"data":{"text/plain":"     target\n0          \n0  0.046912\n1  0.037062\n2  0.033452\n3  0.026276\n4  0.039301\n6  0.666667\n7  0.333333","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>0</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.046912</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.037062</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.033452</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.026276</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.039301</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.333333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['missing'] = (train==-1).sum(axis=1).astype(float)\ntest['missing'] = (test==-1).sum(axis=1).astype(float)","execution_count":237,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features.append('missing')","execution_count":238,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in cat_features:\n    le = LabelEncoder()\n    le.fit(train[c])\n    train[c] = le.transform(train[c])\n    test[c] =le.transform(test[c])","execution_count":239,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OneHotEncoder()\nenc.fit(train[cat_features])","execution_count":240,"outputs":[{"output_type":"execute_result","execution_count":240,"data":{"text/plain":"OneHotEncoder(categorical_features=None, categories=None,\n       dtype=<class 'numpy.float64'>, handle_unknown='error',\n       n_values=None, sparse=True)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_cat = enc.transform(train[cat_features])\nX_t_cat = enc.transform(test[cat_features])","execution_count":241,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_features = [c for c in feature_names if 'ind' in c]\ncount = 0\nfor c in ind_features:\n    if count==0:\n        train['new_ind'] = train[c].astype(str)+'_'\n        test['new_ind'] = test[c].astype(str)+'_'\n        count+=1\n    else :\n        train['new_ind'] += train[c].astype(str)+'_'\n        test['new_ind'] += test[c].astype(str)+'_'","execution_count":242,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['new_ind'].value_counts()#high caldinality","execution_count":243,"outputs":[{"output_type":"execute_result","execution_count":243,"data":{"text/plain":"0_2_1_1_1_1_0_0_0_0_0_0_0_0_7_1_0_0_      102\n0_1_2_1_1_1_0_0_0_0_0_0_0_0_8_1_0_0_       97\n0_1_2_1_1_1_0_0_0_0_0_0_0_0_7_1_0_0_       88\n0_1_3_1_1_1_0_0_0_0_0_0_0_0_6_1_0_0_       82\n0_1_3_1_1_1_0_0_0_0_0_0_0_0_7_1_0_0_       79\n0_1_1_1_1_1_0_0_0_0_0_0_0_0_7_1_0_0_       78\n0_2_0_1_1_1_0_0_0_0_0_0_0_0_7_1_0_0_       74\n1_2_1_1_1_1_0_0_0_0_0_0_0_0_8_1_0_0_       72\n0_1_3_1_1_1_0_0_0_0_0_0_0_0_8_1_0_0_       69\n0_2_1_1_1_1_0_0_0_0_0_0_0_0_8_1_0_0_       68\n0_1_1_1_1_1_0_0_0_0_0_0_0_0_8_1_0_0_       63\n1_1_2_1_1_1_0_0_0_0_0_0_0_0_7_1_0_0_       63\n0_1_2_1_1_1_0_0_0_0_0_0_0_0_6_1_0_0_       61\n1_1_2_1_1_1_0_0_0_0_0_0_0_0_8_1_0_0_       57\n0_1_3_1_1_1_0_0_0_0_0_0_0_0_11_1_0_0_      56\n0_1_2_1_1_1_0_0_0_0_0_0_0_0_9_1_0_0_       54\n0_1_4_1_1_1_0_0_0_0_0_0_0_0_8_1_0_0_       53\n0_1_2_1_1_1_0_0_0_0_0_0_0_0_3_0_0_1_       52\n1_2_1_1_1_1_0_0_0_0_0_0_0_0_7_1_0_0_       51\n0_1_3_1_1_1_0_0_0_0_0_0_0_0_3_0_0_1_       49\n1_1_3_1_1_1_0_0_0_0_0_0_0_0_6_1_0_0_       48\n1_1_1_1_1_1_0_0_0_0_0_0_0_0_8_1_0_0_       44\n0_1_4_1_1_1_0_0_0_0_0_0_0_0_11_1_0_0_      44\n0_1_4_1_1_1_0_0_0_0_0_0_0_0_7_1_0_0_       43\n1_1_3_1_1_1_0_0_0_0_0_0_0_0_7_1_0_0_       41\n1_1_2_1_1_1_0_0_0_0_0_0_0_0_6_1_0_0_       41\n1_1_4_1_1_1_0_0_0_0_0_0_0_0_8_1_0_0_       41\n0_1_5_1_1_1_0_0_0_0_0_0_0_0_6_1_0_0_       41\n0_1_2_1_1_1_0_0_0_0_0_0_0_0_10_1_0_0_      41\n0_1_4_1_1_1_0_0_0_0_0_0_0_0_3_0_0_1_       41\n                                         ... \n2_2_8_2_1_0_0_0_1_0_0_0_0_0_13_1_0_0_       1\n2_1_3_2_1_0_1_0_0_0_0_0_0_0_1_0_1_0_        1\n1_2_5_2_1_0_1_0_0_0_0_0_0_0_8_1_0_0_        1\n5_1_5_2_1_0_1_0_0_0_0_0_0_0_2_0_1_0_        1\n1_1_1_1_5_1_0_0_0_0_0_0_0_0_6_1_0_0_        1\n5_1_10_2_1_0_0_1_0_0_0_0_0_0_13_0_0_0_      1\n6_1_3_2_1_1_0_0_0_0_0_0_0_0_6_1_0_0_        1\n0_1_6_2_2_1_0_0_0_0_0_0_0_0_10_0_0_0_       1\n3_1_9_1_1_1_0_0_0_0_0_0_0_0_13_0_1_0_       1\n2_2_2_2_1_0_0_0_1_0_0_0_0_0_2_0_1_0_        1\n0_3_8_1_1_0_1_0_0_0_0_0_0_0_5_0_0_1_        1\n0_1_6_1_3_0_1_0_0_0_0_0_0_0_4_1_0_0_        1\n6_2_3_2_1_0_0_0_1_0_0_0_0_0_10_1_0_0_       1\n7_1_4_2_1_0_0_0_1_0_0_0_0_0_8_0_1_0_        1\n1_2_8_2_1_1_0_0_0_0_0_0_0_0_7_1_0_0_        1\n0_4_8_2_1_0_1_0_0_0_0_0_0_0_0_0_0_1_        1\n1_1_9_1_5_0_0_0_1_0_0_0_0_0_10_0_0_0_       1\n2_1_6_2_7_0_1_0_0_0_0_0_0_0_11_0_1_0_       1\n0_1_1_1_5_1_0_0_0_0_0_0_0_0_5_0_1_0_        1\n3_1_1_2_1_0_0_1_0_0_0_0_0_0_0_1_0_0_        1\n4_1_3_2_1_0_0_1_0_0_0_0_0_0_12_0_1_0_       1\n2_2_7_2_1_1_0_0_0_0_0_0_0_0_11_1_0_0_       1\n0_3_2_2_1_1_0_0_0_0_0_0_0_0_12_0_0_1_       1\n0_3_9_2_1_0_0_0_1_0_0_0_0_0_5_1_0_0_        1\n1_1_4_2_2_1_0_0_0_0_0_0_0_0_11_1_0_0_       1\n6_1_2_1_1_0_0_1_0_0_0_0_0_0_9_1_0_0_        1\n5_1_6_2_1_0_0_1_0_0_0_1_0_1_4_1_0_0_        1\n2_4_8_2_1_0_1_0_0_0_0_0_0_0_8_0_0_0_        1\n0_1_1_1_1_1_0_0_0_0_0_1_0_1_10_0_0_0_       1\n2_1_1_1_1_1_0_0_0_0_0_0_0_0_0_1_0_0_        1\nName: new_ind, Length: 22454, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_count_features = []\nfor c in cat_features+['new_ind']:\n    break\n    d = pd.concat([train[c],test[c]]).value_counts().to_dict()\n    train['%s_count'%c] = train[c].apply(lambda x:d.get(x,0))\n    test['%s_count'%c] = test[c].apply(lambda x:d.get(x,0))\n    cat_count_features.append('%s_count'%c)","execution_count":244,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = pd.concat([train[c],test[c]]).value_counts().to_dict()","execution_count":245,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d #high caldinality를 대체, 일종의 frequency encoding","execution_count":246,"outputs":[{"output_type":"execute_result","execution_count":246,"data":{"text/plain":"{1: 72719, 2: 20717, 3: 4645, 4: 1892, 0: 27}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[c]","execution_count":247,"outputs":[{"output_type":"execute_result","execution_count":247,"data":{"text/plain":"0        2\n1        1\n2        4\n3        1\n4        2\n5        1\n6        1\n7        1\n8        1\n9        1\n10       2\n11       1\n12       1\n13       1\n14       1\n15       1\n16       2\n17       1\n18       1\n19       1\n20       1\n21       1\n22       3\n23       1\n24       1\n25       1\n26       1\n27       1\n28       2\n29       2\n        ..\n49970    1\n49971    2\n49972    1\n49973    2\n49974    3\n49975    3\n49976    2\n49977    3\n49978    2\n49979    1\n49980    1\n49981    2\n49982    2\n49983    3\n49984    4\n49985    1\n49986    3\n49987    1\n49988    2\n49989    1\n49990    1\n49991    1\n49992    2\n49993    2\n49994    1\n49995    2\n49996    1\n49997    1\n49998    1\n49999    1\nName: ps_ind_02_cat, Length: 50000, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[c].apply(lambda x : d.get(x,0))","execution_count":248,"outputs":[{"output_type":"execute_result","execution_count":248,"data":{"text/plain":"0        20717\n1        72719\n2         1892\n3        72719\n4        20717\n5        72719\n6        72719\n7        72719\n8        72719\n9        72719\n10       20717\n11       72719\n12       72719\n13       72719\n14       72719\n15       72719\n16       20717\n17       72719\n18       72719\n19       72719\n20       72719\n21       72719\n22        4645\n23       72719\n24       72719\n25       72719\n26       72719\n27       72719\n28       20717\n29       20717\n         ...  \n49970    72719\n49971    20717\n49972    72719\n49973    20717\n49974     4645\n49975     4645\n49976    20717\n49977     4645\n49978    20717\n49979    72719\n49980    72719\n49981    20717\n49982    20717\n49983     4645\n49984     1892\n49985    72719\n49986     4645\n49987    72719\n49988    20717\n49989    72719\n49990    72719\n49991    72719\n49992    20717\n49993    20717\n49994    72719\n49995    20717\n49996    72719\n49997    72719\n49998    72719\n49999    72719\nName: ps_ind_02_cat, Length: 50000, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"- ind feature들을 하나로 묶어서, 새로운 카테고리를 만들어 낸것  "},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":249,"outputs":[{"output_type":"execute_result","execution_count":249,"data":{"text/plain":"   id                  ...                                                  new_ind\n0   7                  ...                    2_2_5_2_1_0_1_0_0_0_0_0_0_0_11_0_1_0_\n1   9                  ...                     1_1_7_1_1_0_0_1_0_0_0_0_0_0_3_0_0_1_\n2  13                  ...                    5_4_9_2_1_0_0_1_0_0_0_0_0_0_12_1_0_0_\n3  16                  ...                     0_1_2_1_1_1_0_0_0_0_0_0_0_0_8_1_0_0_\n4  17                  ...                     0_2_0_2_1_1_0_0_0_0_0_0_0_0_9_1_0_0_\n\n[5 rows x 61 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n      <th>ps_ind_01</th>\n      <th>ps_ind_02_cat</th>\n      <th>ps_ind_03</th>\n      <th>ps_ind_04_cat</th>\n      <th>ps_ind_05_cat</th>\n      <th>ps_ind_06_bin</th>\n      <th>ps_ind_07_bin</th>\n      <th>ps_ind_08_bin</th>\n      <th>ps_ind_09_bin</th>\n      <th>ps_ind_10_bin</th>\n      <th>ps_ind_11_bin</th>\n      <th>ps_ind_12_bin</th>\n      <th>ps_ind_13_bin</th>\n      <th>ps_ind_14</th>\n      <th>ps_ind_15</th>\n      <th>ps_ind_16_bin</th>\n      <th>ps_ind_17_bin</th>\n      <th>ps_ind_18_bin</th>\n      <th>ps_reg_01</th>\n      <th>ps_reg_02</th>\n      <th>ps_reg_03</th>\n      <th>ps_car_01_cat</th>\n      <th>ps_car_02_cat</th>\n      <th>ps_car_03_cat</th>\n      <th>ps_car_04_cat</th>\n      <th>ps_car_05_cat</th>\n      <th>ps_car_06_cat</th>\n      <th>ps_car_07_cat</th>\n      <th>ps_car_08_cat</th>\n      <th>ps_car_09_cat</th>\n      <th>ps_car_10_cat</th>\n      <th>ps_car_11_cat</th>\n      <th>ps_car_11</th>\n      <th>ps_car_12</th>\n      <th>ps_car_13</th>\n      <th>ps_car_14</th>\n      <th>ps_car_15</th>\n      <th>ps_calc_01</th>\n      <th>ps_calc_02</th>\n      <th>ps_calc_03</th>\n      <th>ps_calc_04</th>\n      <th>ps_calc_05</th>\n      <th>ps_calc_06</th>\n      <th>ps_calc_07</th>\n      <th>ps_calc_08</th>\n      <th>ps_calc_09</th>\n      <th>ps_calc_10</th>\n      <th>ps_calc_11</th>\n      <th>ps_calc_12</th>\n      <th>ps_calc_13</th>\n      <th>ps_calc_14</th>\n      <th>ps_calc_15_bin</th>\n      <th>ps_calc_16_bin</th>\n      <th>ps_calc_17_bin</th>\n      <th>ps_calc_18_bin</th>\n      <th>ps_calc_19_bin</th>\n      <th>ps_calc_20_bin</th>\n      <th>missing</th>\n      <th>new_ind</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.7</td>\n      <td>0.2</td>\n      <td>0.718070</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>11</td>\n      <td>2</td>\n      <td>0.400000</td>\n      <td>0.883679</td>\n      <td>0.370810</td>\n      <td>3.605551</td>\n      <td>0.6</td>\n      <td>0.5</td>\n      <td>0.2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>5</td>\n      <td>9</td>\n      <td>1</td>\n      <td>5</td>\n      <td>8</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2_2_5_2_1_0_1_0_0_0_0_0_0_0_11_0_1_0_</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.8</td>\n      <td>0.4</td>\n      <td>0.766078</td>\n      <td>12</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>18</td>\n      <td>3</td>\n      <td>0.316228</td>\n      <td>0.618817</td>\n      <td>0.388716</td>\n      <td>2.449490</td>\n      <td>0.3</td>\n      <td>0.1</td>\n      <td>0.3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>9</td>\n      <td>5</td>\n      <td>8</td>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>1_1_7_1_1_0_0_1_0_0_0_0_0_0_3_0_0_1_</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13</td>\n      <td>0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>9</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.000000</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>59</td>\n      <td>1</td>\n      <td>0.316228</td>\n      <td>0.641586</td>\n      <td>0.347275</td>\n      <td>3.316625</td>\n      <td>0.5</td>\n      <td>0.7</td>\n      <td>0.1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>9</td>\n      <td>1</td>\n      <td>8</td>\n      <td>2</td>\n      <td>7</td>\n      <td>4</td>\n      <td>2</td>\n      <td>7</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>5_4_9_2_1_0_0_1_0_0_0_0_0_0_12_1_0_0_</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.9</td>\n      <td>0.2</td>\n      <td>0.580948</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>11</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>103</td>\n      <td>1</td>\n      <td>0.374166</td>\n      <td>0.542949</td>\n      <td>0.294958</td>\n      <td>2.000000</td>\n      <td>0.6</td>\n      <td>0.9</td>\n      <td>0.1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>7</td>\n      <td>1</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0_1_2_1_1_1_0_0_0_0_0_0_0_0_8_1_0_0_</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.7</td>\n      <td>0.6</td>\n      <td>0.840759</td>\n      <td>12</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>81</td>\n      <td>3</td>\n      <td>0.316070</td>\n      <td>0.565832</td>\n      <td>0.365103</td>\n      <td>2.000000</td>\n      <td>0.4</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>6</td>\n      <td>3</td>\n      <td>10</td>\n      <td>2</td>\n      <td>12</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0_2_0_2_1_1_0_0_0_0_0_0_0_0_9_1_0_0_</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_list = [train[num_features + cat_count_features].values, X_cat,]","execution_count":250,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_list = [test[num_features + cat_count_features].values, X_t_cat]","execution_count":251,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_list #sparse matrix로 저장되어 있음","execution_count":252,"outputs":[{"output_type":"execute_result","execution_count":252,"data":{"text/plain":"[array([[0.6, 0.5, 0.2, ..., 0. , 1. , 1. ],\n        [0.3, 0.1, 0.3, ..., 1. , 0. , 2. ],\n        [0.5, 0.7, 0.1, ..., 1. , 0. , 3. ],\n        ...,\n        [0.1, 0. , 0.8, ..., 0. , 0. , 3. ],\n        [0.2, 0.5, 0.8, ..., 1. , 0. , 2. ],\n        [0.8, 0.3, 0.8, ..., 1. , 0. , 3. ]]),\n <50000x183 sparse matrix of type '<class 'numpy.float64'>'\n \twith 700000 stored elements in Compressed Sparse Row format>]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=ssp.hstack(train_list).tocsr()","execution_count":253,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ssp.hstack(train_list)","execution_count":254,"outputs":[{"output_type":"execute_result","execution_count":254,"data":{"text/plain":"<50000x204 sparse matrix of type '<class 'numpy.float64'>'\n\twith 1503317 stored elements in COOrdinate format>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ssp.hstack(train_list).tocsr() #compressed sparse row format으로 바뀜","execution_count":255,"outputs":[{"output_type":"execute_result","execution_count":255,"data":{"text/plain":"<50000x204 sparse matrix of type '<class 'numpy.float64'>'\n\twith 1503317 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = ssp.hstack(test_list).tocsr()","execution_count":256,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Development"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 0.1\nnum_leaves = 15\nmin_data_in_leaf = 2000\nfeature_fraction = 0.6\nnum_boost_round = 10000\nparams = {'objective' : 'binary',\n          'boosting_type' : 'gbdt',\n          'learning_rate' : learning_rate,\n          'num_leaves' : num_leaves,\n          'max_bin' : 256,\n          'feature_fraction': feature_fraction,\n          'verbosity':0,\n          'drop_rate':0.1,\n          'is_usbalance' : False,\n          'max_drop' : 50,\n          'min_child_samples': 10,\n          'min_child_weight' : 150,\n          'min_split_gain' : 0,\n          'subsample' : 0.9\n         }","execution_count":257,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# out of fold stacking\nx_score = []\nfinal_cv_train = np.zeros(len(train_label))\nfinal_cv_pred = np.zeros(len(test_id))    ","execution_count":258,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for s in np.arange(16):\n    break","execution_count":259,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_train = np.zeros(len(train_label))\ncv_pred = np.zeros(len(test_id))","execution_count":260,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params['seed'] = s #앙상블은 다양성이 있어서 좋은 것\n# random num을 바꾸면서 다양성을 확보하려는 코드","execution_count":261,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = kfold.split(X, train_label)","execution_count":262,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_trees = []\nfold_scores = []","execution_count":263,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, (train_fold, validate) in enumerate(kf):\n    break","execution_count":264,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validate","execution_count":265,"outputs":[{"output_type":"execute_result","execution_count":265,"data":{"text/plain":"array([    2,     7,    23, ..., 49993, 49996, 49998])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, label_train = X[train_fold, :], train_label[train_fold]","execution_count":266,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_validate, label_validate = X[validate,:], train_label[validate]","execution_count":267,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = lgbm.Dataset(X_train, label_train)\ndvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)","execution_count":268,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100,\n                            early_stopping_rounds=100)","execution_count":269,"outputs":[{"output_type":"stream","text":"Training until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157512\tvalid_0's gini: 0.118119\nEarly stopping, best iteration is:\n[3]\tvalid_0's binary_logloss: 0.156657\tvalid_0's gini: 0.148781\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"bst.best_iteration","execution_count":270,"outputs":[{"output_type":"execute_result","execution_count":270,"data":{"text/plain":"3"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_trees = []\nfold_scores = []","execution_count":271,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_trees.append(bst.best_iteration)","execution_count":272,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)","execution_count":273,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_train[validate] += bst.predict(X_validate)","execution_count":274,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = Gini(label_validate, cv_train[validate])","execution_count":275,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score","execution_count":276,"outputs":[{"output_type":"execute_result","execution_count":276,"data":{"text/plain":"0.14878108244019966"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fold_scores.append(score)","execution_count":277,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf","execution_count":278,"outputs":[{"output_type":"execute_result","execution_count":278,"data":{"text/plain":"<generator object _BaseKFold.split at 0x7f8a91d21410>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, (train_fold, validate) in enumerate(kf):\n    print('#'*30, '{} of {}'.format(i+1, 5))\n    X_train, X_validate, label_train, label_validate = \\\n        X[train_fold, :], X[validate, :], train_label[train_fold], train_label[validate]\n    dtrain = lgbm.Dataset(X_train, label_train)\n    dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n    bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100,\n                    early_stopping_rounds=100)\n    best_trees.append(bst.best_iteration)\n    cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)\n    cv_train[validate] += bst.predict(X_validate)\n\n    score = Gini(label_validate, cv_train[validate])\n    print(score)\n    fold_scores.append(score)\n\ncv_pred /= NFOLDS","execution_count":279,"outputs":[{"output_type":"stream","text":"############################## 1 of 5\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154076\tvalid_0's gini: 0.228955\nEarly stopping, best iteration is:\n[26]\tvalid_0's binary_logloss: 0.154201\tvalid_0's gini: 0.242028\n0.24202769596100102\n############################## 2 of 5\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155429\tvalid_0's gini: 0.182289\nEarly stopping, best iteration is:\n[37]\tvalid_0's binary_logloss: 0.155086\tvalid_0's gini: 0.193815\n0.1938151975879916\n############################## 3 of 5\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154995\tvalid_0's gini: 0.19683\nEarly stopping, best iteration is:\n[13]\tvalid_0's binary_logloss: 0.155003\tvalid_0's gini: 0.216065\n0.21606454134495545\n############################## 4 of 5\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154693\tvalid_0's gini: 0.195648\nEarly stopping, best iteration is:\n[21]\tvalid_0's binary_logloss: 0.154561\tvalid_0's gini: 0.214999\n0.21499864706873395\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fold_scores","execution_count":280,"outputs":[{"output_type":"execute_result","execution_count":280,"data":{"text/plain":"[0.14878108244019966,\n 0.24202769596100102,\n 0.1938151975879916,\n 0.21606454134495545,\n 0.21499864706873395]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_pred","execution_count":281,"outputs":[{"output_type":"execute_result","execution_count":281,"data":{"text/plain":"array([0.02587586, 0.03045339, 0.02920774, ..., 0.05251369, 0.02505443,\n       0.03028296])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_cv_train += cv_train\nfinal_cv_pred += cv_pred","execution_count":282,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('cv score :')\nprint(Gini(train_label, cv_train))\nprint('current score', Gini(train_label, final_cv_train/(s+1.)), s+1)\nprint(fold_scores)\nprint(best_trees, np.mean(best_trees))","execution_count":283,"outputs":[{"output_type":"stream","text":"cv score :\n0.19809839178931374\ncurrent score 0.19809839178931374 1\n[0.14878108244019966, 0.24202769596100102, 0.1938151975879916, 0.21606454134495545, 0.21499864706873395]\n[3, 26, 37, 13, 21] 20.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_score.append(Gini(train_label, cv_train))","execution_count":284,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_score)","execution_count":285,"outputs":[{"output_type":"stream","text":"[0.19809839178931374]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### cross validation stacking을 총 16번 진행한 것\n#### 학습은 16x5 = 80번 진행하게 됨"},{"metadata":{"trusted":true},"cell_type":"code","source":"for s in range(16):\n    print('#'*30, 'random number outer iteration: {}'.format(s))\n    cv_train = np.zeros(len(train_label))\n    cv_pred = np.zeros(len(test_id))\n\n    params['seed'] = s\n\n    if cv_only:\n        kf = kfold.split(X, train_label)\n\n        best_trees = []\n        fold_scores = []\n\n        for i, (train_fold, validate) in enumerate(kf):\n            print('#'*10, 'inner cross validation system {}'.format(i))\n            X_train, X_validate, label_train, label_validate = \\\n                X[train_fold, :], X[validate, :], train_label[train_fold], train_label[validate]\n            dtrain = lgbm.Dataset(X_train, label_train)\n            dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n            bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100,\n                            early_stopping_rounds=100)\n            best_trees.append(bst.best_iteration)\n            cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)\n            cv_train[validate] += bst.predict(X_validate)\n\n            score = Gini(label_validate, cv_train[validate])\n            print(score)\n            fold_scores.append(score)\n\n        cv_pred /= NFOLDS\n        final_cv_train += cv_train\n        final_cv_pred += cv_pred\n\n        print(\"cv score:\")\n        print(Gini(train_label, cv_train))\n        print(\"current score:\", Gini(train_label, final_cv_train / (s + 1.)), s+1)\n        print(fold_scores)\n        print(best_trees, np.mean(best_trees))\n\n        x_score.append(Gini(train_label, cv_train))\n\nprint(x_score)","execution_count":289,"outputs":[{"output_type":"stream","text":"############################## random number outer iteration: 0\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157512\tvalid_0's gini: 0.118119\nEarly stopping, best iteration is:\n[3]\tvalid_0's binary_logloss: 0.156657\tvalid_0's gini: 0.148781\n0.14878108244019966\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154076\tvalid_0's gini: 0.228955\nEarly stopping, best iteration is:\n[26]\tvalid_0's binary_logloss: 0.154201\tvalid_0's gini: 0.242028\n0.24202769596100102\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155429\tvalid_0's gini: 0.182289\nEarly stopping, best iteration is:\n[37]\tvalid_0's binary_logloss: 0.155086\tvalid_0's gini: 0.193815\n0.1938151975879916\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154995\tvalid_0's gini: 0.19683\nEarly stopping, best iteration is:\n[13]\tvalid_0's binary_logloss: 0.155003\tvalid_0's gini: 0.216065\n0.21606454134495545\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154693\tvalid_0's gini: 0.195648\nEarly stopping, best iteration is:\n[21]\tvalid_0's binary_logloss: 0.154561\tvalid_0's gini: 0.214999\n0.21499864706873395\ncv score:\n0.19809839178931374\ncurrent score: 0.19809839178931374 1\n[0.14878108244019966, 0.24202769596100102, 0.1938151975879916, 0.21606454134495545, 0.21499864706873395]\n[3, 26, 37, 13, 21] 20.0\n############################## random number outer iteration: 1\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157617\tvalid_0's gini: 0.113172\nEarly stopping, best iteration is:\n[2]\tvalid_0's binary_logloss: 0.156849\tvalid_0's gini: 0.160461\n0.16046144473563492\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154264\tvalid_0's gini: 0.221029\nEarly stopping, best iteration is:\n[28]\tvalid_0's binary_logloss: 0.154162\tvalid_0's gini: 0.241948\n0.2419479375667129\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155304\tvalid_0's gini: 0.183454\nEarly stopping, best iteration is:\n[22]\tvalid_0's binary_logloss: 0.15514\tvalid_0's gini: 0.195837\n0.1958370847713256\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155107\tvalid_0's gini: 0.194386\nEarly stopping, best iteration is:\n[9]\tvalid_0's binary_logloss: 0.155244\tvalid_0's gini: 0.219191\n0.21919131582634602\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154734\tvalid_0's gini: 0.195955\nEarly stopping, best iteration is:\n[24]\tvalid_0's binary_logloss: 0.154563\tvalid_0's gini: 0.209939\n0.20993919467404562\ncv score:\n0.19495147083912945\ncurrent score: 0.19765551093258907 2\n[0.16046144473563492, 0.2419479375667129, 0.1958370847713256, 0.21919131582634602, 0.20993919467404562]\n[2, 28, 22, 9, 24] 17.0\n############################## random number outer iteration: 2\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157352\tvalid_0's gini: 0.123191\nEarly stopping, best iteration is:\n[4]\tvalid_0's binary_logloss: 0.156573\tvalid_0's gini: 0.149737\n0.149737051846916\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154029\tvalid_0's gini: 0.231219\nEarly stopping, best iteration is:\n[30]\tvalid_0's binary_logloss: 0.154145\tvalid_0's gini: 0.237896\n0.2378960980043998\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155231\tvalid_0's gini: 0.187005\nEarly stopping, best iteration is:\n[47]\tvalid_0's binary_logloss: 0.154915\tvalid_0's gini: 0.198993\n0.19899324274441485\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155286\tvalid_0's gini: 0.186416\nEarly stopping, best iteration is:\n[11]\tvalid_0's binary_logloss: 0.155187\tvalid_0's gini: 0.222344\n0.22234361731275512\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154348\tvalid_0's gini: 0.2093\nEarly stopping, best iteration is:\n[57]\tvalid_0's binary_logloss: 0.154037\tvalid_0's gini: 0.223053\n0.22305326805227244\ncv score:\n0.19873495232099098\ncurrent score: 0.19872249339453202 3\n[0.149737051846916, 0.2378960980043998, 0.19899324274441485, 0.22234361731275512, 0.22305326805227244]\n[4, 30, 47, 11, 57] 29.8\n############################## random number outer iteration: 3\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157384\tvalid_0's gini: 0.123066\nEarly stopping, best iteration is:\n[11]\tvalid_0's binary_logloss: 0.156067\tvalid_0's gini: 0.152504\n0.15250427216505585\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154232\tvalid_0's gini: 0.219673\nEarly stopping, best iteration is:\n[48]\tvalid_0's binary_logloss: 0.154028\tvalid_0's gini: 0.234865\n0.23486471335907858\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155396\tvalid_0's gini: 0.18286\nEarly stopping, best iteration is:\n[23]\tvalid_0's binary_logloss: 0.15517\tvalid_0's gini: 0.194058\n0.1940578919365227\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155307\tvalid_0's gini: 0.186861\nEarly stopping, best iteration is:\n[14]\tvalid_0's binary_logloss: 0.155\tvalid_0's gini: 0.210446\n0.21044633117374867\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154569\tvalid_0's gini: 0.198321\nEarly stopping, best iteration is:\n[27]\tvalid_0's binary_logloss: 0.154338\tvalid_0's gini: 0.217947\n0.21794729978177238\ncv score:\n0.20048400437507663\ncurrent score: 0.20034688822624766 4\n[0.15250427216505585, 0.23486471335907858, 0.1940578919365227, 0.21044633117374867, 0.21794729978177238]\n[11, 48, 23, 14, 27] 24.6\n############################## random number outer iteration: 4\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157427\tvalid_0's gini: 0.122568\nEarly stopping, best iteration is:\n[1]\tvalid_0's binary_logloss: 0.156959\tvalid_0's gini: 0.154326\n0.15432627066152524\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154116\tvalid_0's gini: 0.227623\nEarly stopping, best iteration is:\n[55]\tvalid_0's binary_logloss: 0.153886\tvalid_0's gini: 0.241123\n0.24112320183003094\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155503\tvalid_0's gini: 0.176047\nEarly stopping, best iteration is:\n[25]\tvalid_0's binary_logloss: 0.155073\tvalid_0's gini: 0.195882\n0.19588177673760526\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155156\tvalid_0's gini: 0.194106\nEarly stopping, best iteration is:\n[6]\tvalid_0's binary_logloss: 0.155627\tvalid_0's gini: 0.218064\n0.21806415673807983\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n","name":"stdout"},{"output_type":"stream","text":"[100]\tvalid_0's binary_logloss: 0.154657\tvalid_0's gini: 0.197467\nEarly stopping, best iteration is:\n[15]\tvalid_0's binary_logloss: 0.154775\tvalid_0's gini: 0.216395\n0.21639469060986274\ncv score:\n0.19170902390189545\ncurrent score: 0.19956582680024038 5\n[0.15432627066152524, 0.24112320183003094, 0.19588177673760526, 0.21806415673807983, 0.21639469060986274]\n[1, 55, 25, 6, 15] 20.4\n############################## random number outer iteration: 5\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157377\tvalid_0's gini: 0.122103\nEarly stopping, best iteration is:\n[19]\tvalid_0's binary_logloss: 0.156031\tvalid_0's gini: 0.146298\n0.14629782463222052\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154104\tvalid_0's gini: 0.227021\nEarly stopping, best iteration is:\n[29]\tvalid_0's binary_logloss: 0.154136\tvalid_0's gini: 0.236023\n0.23602262423218412\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155568\tvalid_0's gini: 0.171928\nEarly stopping, best iteration is:\n[25]\tvalid_0's binary_logloss: 0.15511\tvalid_0's gini: 0.193163\n0.19316348688983798\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.15521\tvalid_0's gini: 0.189371\nEarly stopping, best iteration is:\n[11]\tvalid_0's binary_logloss: 0.155183\tvalid_0's gini: 0.213352\n0.21335243887842273\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154495\tvalid_0's gini: 0.20388\nEarly stopping, best iteration is:\n[27]\tvalid_0's binary_logloss: 0.154485\tvalid_0's gini: 0.212061\n0.21206077242448113\ncv score:\n0.1959168564189482\ncurrent score: 0.20052348784565466 6\n[0.14629782463222052, 0.23602262423218412, 0.19316348688983798, 0.21335243887842273, 0.21206077242448113]\n[19, 29, 25, 11, 27] 22.2\n############################## random number outer iteration: 6\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157305\tvalid_0's gini: 0.121774\nEarly stopping, best iteration is:\n[8]\tvalid_0's binary_logloss: 0.156191\tvalid_0's gini: 0.150916\n0.1509158922277425\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154156\tvalid_0's gini: 0.224876\nEarly stopping, best iteration is:\n[26]\tvalid_0's binary_logloss: 0.154193\tvalid_0's gini: 0.240138\n0.24013838364240192\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155326\tvalid_0's gini: 0.184582\nEarly stopping, best iteration is:\n[24]\tvalid_0's binary_logloss: 0.155065\tvalid_0's gini: 0.198678\n0.19867757037499675\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155302\tvalid_0's gini: 0.186407\nEarly stopping, best iteration is:\n[5]\tvalid_0's binary_logloss: 0.155747\tvalid_0's gini: 0.211391\n0.21139083035943718\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154569\tvalid_0's gini: 0.199423\nEarly stopping, best iteration is:\n[25]\tvalid_0's binary_logloss: 0.154427\tvalid_0's gini: 0.214091\n0.21409102022362786\ncv score:\n0.19616653330518524\ncurrent score: 0.20072604733728336 7\n[0.1509158922277425, 0.24013838364240192, 0.19867757037499675, 0.21139083035943718, 0.21409102022362786]\n[8, 26, 24, 5, 25] 17.6\n############################## random number outer iteration: 7\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157392\tvalid_0's gini: 0.119611\nEarly stopping, best iteration is:\n[14]\tvalid_0's binary_logloss: 0.156151\tvalid_0's gini: 0.137849\n0.1378485257990123\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.15407\tvalid_0's gini: 0.22782\nEarly stopping, best iteration is:\n[28]\tvalid_0's binary_logloss: 0.154058\tvalid_0's gini: 0.242769\n0.24276927932916972\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155558\tvalid_0's gini: 0.176122\nEarly stopping, best iteration is:\n[12]\tvalid_0's binary_logloss: 0.155496\tvalid_0's gini: 0.194982\n0.19498171447999907\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.15547\tvalid_0's gini: 0.179586\nEarly stopping, best iteration is:\n[12]\tvalid_0's binary_logloss: 0.155087\tvalid_0's gini: 0.217707\n0.21770734593459748\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154671\tvalid_0's gini: 0.19606\nEarly stopping, best iteration is:\n[24]\tvalid_0's binary_logloss: 0.154487\tvalid_0's gini: 0.213213\n0.2132134585177659\ncv score:\n0.1985349299198412\ncurrent score: 0.2013402950643023 8\n[0.1378485257990123, 0.24276927932916972, 0.19498171447999907, 0.21770734593459748, 0.2132134585177659]\n[14, 28, 12, 12, 24] 18.0\n############################## random number outer iteration: 8\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157491\tvalid_0's gini: 0.117571\nEarly stopping, best iteration is:\n[16]\tvalid_0's binary_logloss: 0.156211\tvalid_0's gini: 0.137317\n0.13731736883279536\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154039\tvalid_0's gini: 0.228583\nEarly stopping, best iteration is:\n[22]\tvalid_0's binary_logloss: 0.154299\tvalid_0's gini: 0.24292\n0.24292031118218352\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155311\tvalid_0's gini: 0.186959\nEarly stopping, best iteration is:\n[20]\tvalid_0's binary_logloss: 0.155207\tvalid_0's gini: 0.195849\n0.19584896491426074\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155128\tvalid_0's gini: 0.193769\nEarly stopping, best iteration is:\n[22]\tvalid_0's binary_logloss: 0.154714\tvalid_0's gini: 0.213881\n0.21388056424891888\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154608\tvalid_0's gini: 0.201207\nEarly stopping, best iteration is:\n[43]\tvalid_0's binary_logloss: 0.154319\tvalid_0's gini: 0.215738\n0.2157377956807173\ncv score:\n0.2010720883565318\ncurrent score: 0.2019922593596014 9\n[0.13731736883279536, 0.24292031118218352, 0.19584896491426074, 0.21388056424891888, 0.2157377956807173]\n[16, 22, 20, 22, 43] 24.6\n############################## random number outer iteration: 9\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157463\tvalid_0's gini: 0.116797\nEarly stopping, best iteration is:\n[26]\tvalid_0's binary_logloss: 0.156219\tvalid_0's gini: 0.139977\n0.1399765476381051\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154195\tvalid_0's gini: 0.224055\nEarly stopping, best iteration is:\n[25]\tvalid_0's binary_logloss: 0.154318\tvalid_0's gini: 0.23844\n0.23844026520514602\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155388\tvalid_0's gini: 0.180715\nEarly stopping, best iteration is:\n[24]\tvalid_0's binary_logloss: 0.155077\tvalid_0's gini: 0.19717\n0.19717048938551662\n########## inner cross validation system 3\n","name":"stdout"},{"output_type":"stream","text":"Training until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155137\tvalid_0's gini: 0.192642\nEarly stopping, best iteration is:\n[8]\tvalid_0's binary_logloss: 0.15543\tvalid_0's gini: 0.215906\n0.2159062739138401\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154406\tvalid_0's gini: 0.205339\nEarly stopping, best iteration is:\n[27]\tvalid_0's binary_logloss: 0.154281\tvalid_0's gini: 0.224541\n0.22454120881146827\ncv score:\n0.19650181434249192\ncurrent score: 0.20205523356970292 10\n[0.1399765476381051, 0.23844026520514602, 0.19717048938551662, 0.2159062739138401, 0.22454120881146827]\n[26, 25, 24, 8, 27] 22.0\n############################## random number outer iteration: 10\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157597\tvalid_0's gini: 0.112872\nEarly stopping, best iteration is:\n[9]\tvalid_0's binary_logloss: 0.156053\tvalid_0's gini: 0.160461\n0.16046144473563495\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.15409\tvalid_0's gini: 0.225686\nEarly stopping, best iteration is:\n[41]\tvalid_0's binary_logloss: 0.153847\tvalid_0's gini: 0.24265\n0.24265049023129373\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155414\tvalid_0's gini: 0.18068\nEarly stopping, best iteration is:\n[15]\tvalid_0's binary_logloss: 0.155471\tvalid_0's gini: 0.18919\n0.1891898619385961\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155184\tvalid_0's gini: 0.190695\nEarly stopping, best iteration is:\n[24]\tvalid_0's binary_logloss: 0.154841\tvalid_0's gini: 0.207692\n0.20769225096562982\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154562\tvalid_0's gini: 0.205013\nEarly stopping, best iteration is:\n[59]\tvalid_0's binary_logloss: 0.15433\tvalid_0's gini: 0.212172\n0.21217195671300665\ncv score:\n0.19943657110137733\ncurrent score: 0.2023450508517313 11\n[0.16046144473563495, 0.24265049023129373, 0.1891898619385961, 0.20769225096562982, 0.21217195671300665]\n[9, 41, 15, 24, 59] 29.6\n############################## random number outer iteration: 11\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157299\tvalid_0's gini: 0.122453\nEarly stopping, best iteration is:\n[16]\tvalid_0's binary_logloss: 0.156033\tvalid_0's gini: 0.143837\n0.14383662765670407\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.15439\tvalid_0's gini: 0.216368\nEarly stopping, best iteration is:\n[27]\tvalid_0's binary_logloss: 0.154204\tvalid_0's gini: 0.238372\n0.23837182005827454\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155302\tvalid_0's gini: 0.18078\nEarly stopping, best iteration is:\n[39]\tvalid_0's binary_logloss: 0.155063\tvalid_0's gini: 0.189398\n0.18939804730050627\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.15534\tvalid_0's gini: 0.189754\nEarly stopping, best iteration is:\n[9]\tvalid_0's binary_logloss: 0.155308\tvalid_0's gini: 0.218055\n0.21805508046962874\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154528\tvalid_0's gini: 0.203219\nEarly stopping, best iteration is:\n[25]\tvalid_0's binary_logloss: 0.154409\tvalid_0's gini: 0.215483\n0.21548309289730933\ncv score:\n0.19454039422376532\ncurrent score: 0.20204014694239084 12\n[0.14383662765670407, 0.23837182005827454, 0.18939804730050627, 0.21805508046962874, 0.21548309289730933]\n[16, 27, 39, 9, 25] 23.2\n############################## random number outer iteration: 12\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157421\tvalid_0's gini: 0.11824\nEarly stopping, best iteration is:\n[19]\tvalid_0's binary_logloss: 0.156046\tvalid_0's gini: 0.148677\n0.14867700056396543\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.15414\tvalid_0's gini: 0.226686\nEarly stopping, best iteration is:\n[24]\tvalid_0's binary_logloss: 0.15436\tvalid_0's gini: 0.235869\n0.235869329729687\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155557\tvalid_0's gini: 0.174608\nEarly stopping, best iteration is:\n[19]\tvalid_0's binary_logloss: 0.155214\tvalid_0's gini: 0.194954\n0.19495399414648384\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155377\tvalid_0's gini: 0.184686\nEarly stopping, best iteration is:\n[12]\tvalid_0's binary_logloss: 0.155201\tvalid_0's gini: 0.202994\n0.20299358024187114\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154622\tvalid_0's gini: 0.197566\nEarly stopping, best iteration is:\n[40]\tvalid_0's binary_logloss: 0.154247\tvalid_0's gini: 0.215794\n0.21579395509175817\ncv score:\n0.19620755715212543\ncurrent score: 0.20198186181915664 13\n[0.14867700056396543, 0.235869329729687, 0.19495399414648384, 0.20299358024187114, 0.21579395509175817]\n[19, 24, 19, 12, 40] 22.8\n############################## random number outer iteration: 13\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157558\tvalid_0's gini: 0.111238\nEarly stopping, best iteration is:\n[23]\tvalid_0's binary_logloss: 0.156017\tvalid_0's gini: 0.150982\n0.15098207472513056\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154091\tvalid_0's gini: 0.229122\nEarly stopping, best iteration is:\n[26]\tvalid_0's binary_logloss: 0.154214\tvalid_0's gini: 0.237797\n0.2377971070895031\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155297\tvalid_0's gini: 0.185647\nEarly stopping, best iteration is:\n[40]\tvalid_0's binary_logloss: 0.154998\tvalid_0's gini: 0.194247\n0.19424740850239203\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.15542\tvalid_0's gini: 0.183464\nEarly stopping, best iteration is:\n[10]\tvalid_0's binary_logloss: 0.155271\tvalid_0's gini: 0.212163\n0.21216344771133377\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154623\tvalid_0's gini: 0.205269\nEarly stopping, best iteration is:\n[28]\tvalid_0's binary_logloss: 0.154465\tvalid_0's gini: 0.215446\n0.21544565328994872\ncv score:\n0.19597924166161715\ncurrent score: 0.2017881141864234 14\n[0.15098207472513056, 0.2377971070895031, 0.19424740850239203, 0.21216344771133377, 0.21544565328994872]\n[23, 26, 40, 10, 28] 25.4\n############################## random number outer iteration: 14\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157419\tvalid_0's gini: 0.119863\nEarly stopping, best iteration is:\n[13]\tvalid_0's binary_logloss: 0.156014\tvalid_0's gini: 0.151547\n0.1515471714335978\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154116\tvalid_0's gini: 0.227233\nEarly stopping, best iteration is:\n[31]\tvalid_0's binary_logloss: 0.154124\tvalid_0's gini: 0.240186\n0.2401858992815523\n########## inner cross validation system 2\n","name":"stdout"},{"output_type":"stream","text":"Training until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155496\tvalid_0's gini: 0.181522\nEarly stopping, best iteration is:\n[16]\tvalid_0's binary_logloss: 0.155388\tvalid_0's gini: 0.189134\n0.18913442127156566\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155254\tvalid_0's gini: 0.188693\nEarly stopping, best iteration is:\n[21]\tvalid_0's binary_logloss: 0.154676\tvalid_0's gini: 0.217384\n0.2173840038710284\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154921\tvalid_0's gini: 0.189328\nEarly stopping, best iteration is:\n[10]\tvalid_0's binary_logloss: 0.155131\tvalid_0's gini: 0.211458\n0.21145776783926373\ncv score:\n0.19861070284530505\ncurrent score: 0.20208989203785233 15\n[0.1515471714335978, 0.2401858992815523, 0.18913442127156566, 0.2173840038710284, 0.21145776783926373]\n[13, 31, 16, 21, 10] 18.2\n############################## random number outer iteration: 15\n########## inner cross validation system 0\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.157474\tvalid_0's gini: 0.118888\nEarly stopping, best iteration is:\n[7]\tvalid_0's binary_logloss: 0.156288\tvalid_0's gini: 0.149987\n0.14998707461482638\n########## inner cross validation system 1\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154387\tvalid_0's gini: 0.216575\nEarly stopping, best iteration is:\n[36]\tvalid_0's binary_logloss: 0.154146\tvalid_0's gini: 0.233948\n0.2339477746559501\n########## inner cross validation system 2\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.1556\tvalid_0's gini: 0.175945\nEarly stopping, best iteration is:\n[27]\tvalid_0's binary_logloss: 0.155139\tvalid_0's gini: 0.19314\n0.1931397266039678\n########## inner cross validation system 3\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.155334\tvalid_0's gini: 0.182807\nEarly stopping, best iteration is:\n[15]\tvalid_0's binary_logloss: 0.154877\tvalid_0's gini: 0.217244\n0.2172444562435934\n########## inner cross validation system 4\nTraining until validation scores don't improve for 100 rounds.\n[100]\tvalid_0's binary_logloss: 0.154699\tvalid_0's gini: 0.195549\nEarly stopping, best iteration is:\n[54]\tvalid_0's binary_logloss: 0.154376\tvalid_0's gini: 0.209113\n0.20911268697822089\ncv score:\n0.19791748817713006\ncurrent score: 0.20208001550705945 16\n[0.14998707461482638, 0.2339477746559501, 0.1931397266039678, 0.2172444562435934, 0.20911268697822089]\n[7, 36, 27, 15, 54] 27.8\n[0.19809839178931374, 0.19809839178931374, 0.19495147083912945, 0.19873495232099098, 0.20048400437507663, 0.19170902390189545, 0.1959168564189482, 0.19616653330518524, 0.1985349299198412, 0.2010720883565318, 0.19650181434249192, 0.19943657110137733, 0.19454039422376532, 0.19620755715212543, 0.19597924166161715, 0.19861070284530505, 0.19791748817713006]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 결국 다양성을 위한 작업"},{"metadata":{},"cell_type":"markdown","source":"## 정리\n- 카테고리 인코딩 후 왜 합치는가?(1_3_0_)이런식으로?\n    - ind라는 feature는 카테고리 피쳐였음, 합쳐야 한다는 의견이 있었음\n    - 합쳐보니까 성능이 올라갔음\n    - ps_ind_01이런게 뭘 의미하는지 몰라서 그런 것\n    - 타이타닉으로 생각해보면 (남자_1_C, 남자_1_S, 여자_2_C, 남자_2_S...)이런게 만들어지는것임\n- 포르투가 어려웠던 이유 ==> 비식별화 때문"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}