{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian A/B/C test.\n",
    "### Calculating Each Advertisement's Probability\n",
    "- Using <a href=\"https://en.wikipedia.org/wiki/Beta_distribution\">$Beta \\space Distribution$</a>.\n",
    "- Without calculating Integral of joint distribution, approximate the Bayesian probability of each advertisement.\n",
    "    - Monte Carlo Simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import pandas as pd\n",
    "from scipy.stats import beta, bernoulli\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_genrator(conversion_rate, n_impression):\n",
    "    return np.array(bernoulli(conversion_rate).rvs(n_impression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A \n",
      " Counts: 8500\n",
      " Conversions: 1500\n",
      "\n",
      "B \n",
      " Counts: 8500\n",
      " Conversions: 1410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = dummy_genrator(0.177470, 8500)\n",
    "b = dummy_genrator(0.165777, 8500)\n",
    "imp_a = len(a)\n",
    "imp_b = len(b)\n",
    "conv_a = 1500\n",
    "conv_b = 1410\n",
    "print(\"A \\n Counts: {}\\n Conversions: {}\\n\".format(imp_a, conv_a))\n",
    "print(\"B \\n Counts: {}\\n Conversions: {}\\n\".format(imp_b, conv_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14279551])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta(1501,8501).rvs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (1,2)\n",
    "a.count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation by Formula\n",
    "- Formulas By Evan Miller\n",
    "- http://www.evanmiller.org/bayesian-ab-testing.html\n",
    ">This page collects a few formulas I’ve derived for evaluating A/B tests in a Bayesian context. The formulas on this page are closed-form, so you don’t need to do complicated integral evaluations; they can be computed with simple loops and a decent math library. The advantage of Bayesian formulas over the traditional frequentist formulas is that you don’t have to collect a pre-ordained sample size in order to get a valid result. (See How Not To Run An A/B Test for more context on the “peeking” problem, and Simple Sequential A/B Testing for a frequentist solution to the problem.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\rm Pr}(p_C > \\max{\\{p_A, p_B\\}}) = \\int_0^1 \\int_0^{p_C} \\int_0^{p_C} f(p_A) f(p_B) f(p_C) dp_A dp_B dp_C$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "total = 8000\n",
    "cv_a = 1600\n",
    "cv_b = 1500\n",
    "cv_c = 1580\n",
    "\n",
    "posterior_list_a = beta(cv_a+1, total-cv_a+1).rvs(n)\n",
    "posterior_list_b = beta(cv_b+1, total-cv_b+1).rvs(n)\n",
    "posterior_list_c = beta(cv_c+1, total-cv_c+1).rvs(n)\n",
    "\n",
    "prob_a = ((posterior_list_a > posterior_list_c).sum())/(n)\n",
    "prob_b = ((posterior_list_b > posterior_list_a).sum())/(n)\n",
    "prob_c = ((posterior_list_c > posterior_list_a).sum())/(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does Integration take place into 3-Dimension?\n",
    "- Can it be solved by Monte Carlo simulation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a win: 0.65497\n",
      "b win: 0.02298\n",
      "c win: 0.34503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02298"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 200000\n",
    "total = 8000\n",
    "cv_a = 1600\n",
    "cv_b = 1500\n",
    "cv_c = 1580\n",
    "\n",
    "posterior_list_a = beta(cv_a+1, total-cv_a+1).rvs(n)\n",
    "posterior_list_b = beta(cv_b+1, total-cv_b+1).rvs(n)\n",
    "posterior_list_c = beta(cv_c+1, total-cv_c+1).rvs(n)\n",
    "\n",
    "prob_a = ((posterior_list_a > posterior_list_c).sum())/(n)\n",
    "prob_b = ((posterior_list_b > posterior_list_a).sum())/(n)\n",
    "prob_c = ((posterior_list_c > posterior_list_a).sum())/(n)\n",
    "\n",
    "print('a win:', prob_a)\n",
    "print('b win:', prob_b)\n",
    "print('c win:', prob_c)\n",
    "\n",
    "prob_a + prob_b + prob_c - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with Dynamic Yield's Bayesian Probability Calculator\n",
    "<a href=\"https://marketing.dynamicyield.com/bayesian-calculator/\">Dynamic Yield's BAYESIAN A/B TESTING CALCULATOR</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Dynamic_Yield](dynamic_yield.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "- Total Probability of Advertisements Exceeds 1.0  \n",
    "- <a href=\"https://en.wikipedia.org/wiki/Probability_axioms\">$Probability\\space Exioms$</a>\n",
    "    - $P(\\Omega) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment -01\n",
    "- Calculating bayesian probability for 100 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Count : 1    The Error of total Probability :  0.022710000000000008\n",
      "Experiment Count : 2    The Error of total Probability :  0.02228500000000011\n",
      "Experiment Count : 3    The Error of total Probability :  0.02312499999999984\n",
      "Experiment Count : 4    The Error of total Probability :  0.022559999999999913\n",
      "Experiment Count : 5    The Error of total Probability :  0.022599999999999953\n",
      "Experiment Count : 6    The Error of total Probability :  0.022800000000000153\n",
      "Experiment Count : 7    The Error of total Probability :  0.02289999999999992\n",
      "Experiment Count : 8    The Error of total Probability :  0.02251000000000003\n",
      "Experiment Count : 9    The Error of total Probability :  0.023070000000000146\n",
      "Experiment Count : 10    The Error of total Probability :  0.023015000000000008\n",
      "Experiment Count : 11    The Error of total Probability :  0.023085000000000022\n",
      "\n",
      "\n",
      "Experiment Count : 12    The Error of total Probability :  0.022645000000000026\n",
      "Experiment Count : 13    The Error of total Probability :  0.022445000000000048\n",
      "Experiment Count : 14    The Error of total Probability :  0.022399999999999975\n",
      "Experiment Count : 15    The Error of total Probability :  0.022994999999999877\n",
      "Experiment Count : 16    The Error of total Probability :  0.023174999999999946\n",
      "Experiment Count : 17    The Error of total Probability :  0.022384999999999877\n",
      "Experiment Count : 18    The Error of total Probability :  0.02257500000000001\n",
      "Experiment Count : 19    The Error of total Probability :  0.02313999999999994\n",
      "Experiment Count : 20    The Error of total Probability :  0.02281500000000003\n",
      "Experiment Count : 21    The Error of total Probability :  0.02307999999999999\n",
      "\n",
      "\n",
      "Experiment Count : 22    The Error of total Probability :  0.022549999999999848\n",
      "Experiment Count : 23    The Error of total Probability :  0.022790000000000088\n",
      "Experiment Count : 24    The Error of total Probability :  0.02283500000000016\n",
      "Experiment Count : 25    The Error of total Probability :  0.022244999999999848\n",
      "Experiment Count : 26    The Error of total Probability :  0.022379999999999844\n",
      "Experiment Count : 27    The Error of total Probability :  0.02303999999999995\n",
      "Experiment Count : 28    The Error of total Probability :  0.022629999999999928\n",
      "Experiment Count : 29    The Error of total Probability :  0.022924999999999862\n",
      "Experiment Count : 30    The Error of total Probability :  0.02271999999999985\n",
      "Experiment Count : 31    The Error of total Probability :  0.023360000000000047\n",
      "\n",
      "\n",
      "Experiment Count : 32    The Error of total Probability :  0.023070000000000146\n",
      "Experiment Count : 33    The Error of total Probability :  0.023194999999999855\n",
      "Experiment Count : 34    The Error of total Probability :  0.023255000000000026\n",
      "Experiment Count : 35    The Error of total Probability :  0.022904999999999953\n",
      "Experiment Count : 36    The Error of total Probability :  0.022829999999999906\n",
      "Experiment Count : 37    The Error of total Probability :  0.02246999999999999\n",
      "Experiment Count : 38    The Error of total Probability :  0.02307999999999999\n",
      "Experiment Count : 39    The Error of total Probability :  0.022364999999999968\n",
      "Experiment Count : 40    The Error of total Probability :  0.023050000000000015\n",
      "Experiment Count : 41    The Error of total Probability :  0.02246999999999999\n",
      "\n",
      "\n",
      "Experiment Count : 42    The Error of total Probability :  0.022909999999999986\n",
      "Experiment Count : 43    The Error of total Probability :  0.022854999999999848\n",
      "Experiment Count : 44    The Error of total Probability :  0.022604999999999986\n",
      "Experiment Count : 45    The Error of total Probability :  0.022215000000000096\n",
      "Experiment Count : 46    The Error of total Probability :  0.022340000000000027\n",
      "Experiment Count : 47    The Error of total Probability :  0.02289999999999992\n",
      "Experiment Count : 48    The Error of total Probability :  0.02295999999999987\n",
      "Experiment Count : 49    The Error of total Probability :  0.023089999999999833\n",
      "Experiment Count : 50    The Error of total Probability :  0.02234999999999987\n",
      "Experiment Count : 51    The Error of total Probability :  0.022764999999999924\n",
      "\n",
      "\n",
      "Experiment Count : 52    The Error of total Probability :  0.022405000000000008\n",
      "Experiment Count : 53    The Error of total Probability :  0.02289500000000011\n",
      "Experiment Count : 54    The Error of total Probability :  0.02306000000000008\n",
      "Experiment Count : 55    The Error of total Probability :  0.023435000000000095\n",
      "Experiment Count : 56    The Error of total Probability :  0.022845000000000004\n",
      "Experiment Count : 57    The Error of total Probability :  0.02283499999999994\n",
      "Experiment Count : 58    The Error of total Probability :  0.022974999999999968\n",
      "Experiment Count : 59    The Error of total Probability :  0.0224899999999999\n",
      "Experiment Count : 60    The Error of total Probability :  0.022760000000000113\n",
      "Experiment Count : 61    The Error of total Probability :  0.022495000000000154\n",
      "\n",
      "\n",
      "Experiment Count : 62    The Error of total Probability :  0.023460000000000036\n",
      "Experiment Count : 63    The Error of total Probability :  0.02245000000000008\n",
      "Experiment Count : 64    The Error of total Probability :  0.023004999999999942\n",
      "Experiment Count : 65    The Error of total Probability :  0.022704999999999975\n",
      "Experiment Count : 66    The Error of total Probability :  0.022440000000000015\n",
      "Experiment Count : 67    The Error of total Probability :  0.022589999999999888\n",
      "Experiment Count : 68    The Error of total Probability :  0.02212000000000014\n",
      "Experiment Count : 69    The Error of total Probability :  0.02263499999999996\n",
      "Experiment Count : 70    The Error of total Probability :  0.022710000000000008\n",
      "Experiment Count : 71    The Error of total Probability :  0.023270000000000124\n",
      "\n",
      "\n",
      "Experiment Count : 72    The Error of total Probability :  0.0233000000000001\n",
      "Experiment Count : 73    The Error of total Probability :  0.022499999999999964\n",
      "Experiment Count : 74    The Error of total Probability :  0.022565000000000168\n",
      "Experiment Count : 75    The Error of total Probability :  0.022625000000000117\n",
      "Experiment Count : 76    The Error of total Probability :  0.022950000000000026\n",
      "Experiment Count : 77    The Error of total Probability :  0.022584999999999855\n",
      "Experiment Count : 78    The Error of total Probability :  0.022584999999999855\n",
      "Experiment Count : 79    The Error of total Probability :  0.022545000000000037\n",
      "Experiment Count : 80    The Error of total Probability :  0.022710000000000008\n",
      "Experiment Count : 81    The Error of total Probability :  0.022524999999999906\n",
      "\n",
      "\n",
      "Experiment Count : 82    The Error of total Probability :  0.022669999999999968\n",
      "Experiment Count : 83    The Error of total Probability :  0.02275999999999989\n",
      "Experiment Count : 84    The Error of total Probability :  0.022765000000000146\n",
      "Experiment Count : 85    The Error of total Probability :  0.023205000000000142\n",
      "Experiment Count : 86    The Error of total Probability :  0.022970000000000157\n",
      "Experiment Count : 87    The Error of total Probability :  0.02303500000000014\n",
      "Experiment Count : 88    The Error of total Probability :  0.022540000000000004\n",
      "Experiment Count : 89    The Error of total Probability :  0.023455000000000004\n",
      "Experiment Count : 90    The Error of total Probability :  0.023109999999999964\n",
      "Experiment Count : 91    The Error of total Probability :  0.02303500000000014\n",
      "\n",
      "\n",
      "Experiment Count : 92    The Error of total Probability :  0.022340000000000027\n",
      "Experiment Count : 93    The Error of total Probability :  0.02237\n",
      "Experiment Count : 94    The Error of total Probability :  0.022739999999999982\n",
      "Experiment Count : 95    The Error of total Probability :  0.02281999999999984\n",
      "Experiment Count : 96    The Error of total Probability :  0.02324499999999996\n",
      "Experiment Count : 97    The Error of total Probability :  0.022584999999999855\n",
      "Experiment Count : 98    The Error of total Probability :  0.022395000000000165\n",
      "Experiment Count : 99    The Error of total Probability :  0.022904999999999953\n",
      "Experiment Count : 100    The Error of total Probability :  0.02275500000000008\n",
      "Mean Error of Probability : 0.02277639999999999    Variance of Errors :  9.306804000000436e-08\n"
     ]
    }
   ],
   "source": [
    "total_prob_error = []\n",
    "for i in range(0,100):\n",
    "    posterior_list_a = beta(cv_a+1, total-cv_a+1).rvs(n)\n",
    "    posterior_list_b = beta(cv_b+1, total-cv_b+1).rvs(n)\n",
    "    posterior_list_c = beta(cv_c+1, total-cv_c+1).rvs(n)\n",
    "\n",
    "    prob_a = ((posterior_list_a > posterior_list_c).sum())/(n)\n",
    "    prob_b = ((posterior_list_b > posterior_list_a).sum())/(n)\n",
    "    prob_c = ((posterior_list_c > posterior_list_a).sum())/(n)\n",
    "    \n",
    "    total_prob_error.append(0)\n",
    "    total_prob_error[i] = prob_a + prob_b + prob_c - 1\n",
    "    \n",
    "    print('Experiment Count :',i+1,  '   The Error of total Probability : ', prob_a + prob_b + prob_c - 1)\n",
    "    if (i % 10 == 0) & (i != 0) :\n",
    "        print('\\n')\n",
    "        \n",
    "print('Mean Error of Probability :',np.mean(total_prob_error), \\\n",
    "      '   Variance of Errors : ', np.var(total_prob_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 결과 정리\n",
    "- 오차는 __평균 0.0228__에 __분산은 0.000000135__\n",
    "- 0.023정도의 __오차를 무시__해도 되는가?\n",
    "> #### Thompson Sampling과 Bayesian Probability 계산의 접점?\n",
    "    - Thompson Sampling은 쭉 진행하고, 기준 Traffic 시점에 Bayesian Probability 계산(Thompson Sampling하면서 갖고 있는 각 대안들의 Conversion과 Count 정보를 이용한다. \n",
    "        - A : Beta(cv_a + 1, cnt_a - cv_a + 1).rvs(cnt_a)\n",
    "        - B : Beta(cv_b + 1, cnt_b - cv_b + 1).rvs(cnt_b)\n",
    "        - C : Beta(cv_c + 1, cnt_c - cv_c + 1).rvs(cnt_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment -02\n",
    "> 4 Ads, A/B/C/D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a win: 0.6504\n",
      "b win: 0.02315\n",
      "c win: 0.3496\n",
      "d win: 0.0075\n",
      "zero 0.0\n",
      "1.03065\n"
     ]
    }
   ],
   "source": [
    "n = 20000 #num of random samples\n",
    "total = 8000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv_a = 1600\n",
    "cv_b = 1500\n",
    "cv_c = 1580\n",
    "cv_d = 1480\n",
    "cv_zero = 0\n",
    "\n",
    "\n",
    "\n",
    "posterior_list_a = beta(cv_a+1, total-cv_a+1).rvs(n)\n",
    "posterior_list_b = beta(cv_b+1, total-cv_b+1).rvs(n)\n",
    "posterior_list_c = beta(cv_c+1, total-cv_c+1).rvs(n)\n",
    "posterior_list_d = beta(cv_d+1, total-cv_d+1).rvs(n)\n",
    "posterior_list_zero = beta(cv_zero+1, total-cv_zero+1).rvs(n)\n",
    "\n",
    "prob_a = ((posterior_list_a > posterior_list_c).sum())/(n)\n",
    "prob_b = ((posterior_list_b > posterior_list_a).sum())/(n)\n",
    "prob_c = ((posterior_list_c > posterior_list_a).sum())/(n)\n",
    "prob_d = ((posterior_list_d > posterior_list_a).sum())/(n)\n",
    "prob_zero = ((posterior_list_zero > posterior_list_a).sum())/(n)\n",
    "\n",
    "\n",
    "print('a win:', prob_a)\n",
    "print('b win:', prob_b)\n",
    "print('c win:', prob_c)\n",
    "print('d win:', prob_d)\n",
    "print('zero',prob_zero)\n",
    "print(prob_a+prob_b+prob_c+prob_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 결과\n",
    "- 오차 값이 증가했지만 결과 값은 Bayesian Calculator와 비슷하게 나오는 것을 확인"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Problem\n",
    "- cv 가장 큰 것과 두 번째 큰 것이 정해지지 않으면, 계산 결과가 엉망으로 나오는 경우가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] cv를 순서대로 정리하는 코드 필요 또는 가장 큰 cv나오는 대안을 선정하는 코드 필요\n",
    "- [2] 정리 후 abcd 객체를 만들어서 전달하는 코드로 업데이트\n",
    "- [3] 대안이 2개일 때 3개일 때 4개일 때 달라지면?\n",
    "    - 4개까지 안에 대한 cv와 impression을 만들어두고 들어오는 값에 따라서 값을 업데이트 하는 방식으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1], [2] 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1500, 1480, 1580]\n",
      "[1500, 1480]\n",
      "[1480]\n",
      "[1500, 1480, 1580, 1600]\n",
      "3 win: 0.65855\n",
      "2 win: 0.34145\n",
      "0 win: 0.024\n",
      "1 win: 0.00835\n"
     ]
    }
   ],
   "source": [
    "cv_1 = 1500\n",
    "cv_2 = 1480\n",
    "cv_3 = 1580\n",
    "cv_4 = 1600\n",
    "\n",
    "ads_rvs = [cv_1, cv_2, cv_3, cv_4]\n",
    "sorted_rvs = sorted(ads_rvs, reverse=True)\n",
    "max_rvs = np.max(ads_rvs)\n",
    "win_index_1st = ads_rvs.index(sorted_rvs[0]) #choose best ad\n",
    "\n",
    "print(win_index)\n",
    "#print('win index?',win_index+1)\n",
    "\n",
    "# for i in range(len(ads_rvs)) : \n",
    "#     print('ads list', ads_rvs)\n",
    "#     max_rvs = np.max(ads_rvs)\n",
    "#     win_index = ads_rvs.index(sorted_rvs[0])\n",
    "#     print('win index?',win_index+1)\n",
    "#     sorted_rvs.pop(0)\n",
    "#     print(ads_rvs)\n",
    "    \n",
    "posterior_list_best = beta(ads_rvs[win_index_1st]+1, total-ads_rvs[win_index_1st]+1).rvs(n) #best ad's posterior\n",
    "ads_rvs.pop(win_index_1st)\n",
    "first = sorted_rvs.pop(0)\n",
    "\n",
    "win_index_2nd = ads_rvs.index(sorted_rvs[0])\n",
    "print(ads_rvs)\n",
    "\n",
    "posterior_list_2nd = beta(ads_rvs[win_index_2nd]+1, total-ads_rvs[win_index_2nd]+1).rvs(n) #second ad's posterior\n",
    "ads_rvs.pop(win_index_2nd)\n",
    "second = sorted_rvs.pop(0)\n",
    "\n",
    "win_index_3rd = ads_rvs.index(sorted_rvs[0])\n",
    "print(ads_rvs)\n",
    "\n",
    "posterior_list_3rd = beta(ads_rvs[win_index_3rd]+1, total-ads_rvs[win_index_3rd]+1).rvs(n) #third ad's posterior\n",
    "ads_rvs.pop(win_index_3rd)\n",
    "third = sorted_rvs.pop(0)\n",
    "\n",
    "win_index_4th = ads_rvs.index(sorted_rvs[0])\n",
    "print(ads_rvs)\n",
    "\n",
    "posterior_list_4th = beta(ads_rvs[win_index_4th]+1, total-ads_rvs[win_index_4th]+1).rvs(n) #4th ad's posterior\n",
    "\n",
    "\n",
    "prob_a = ((posterior_list_best > posterior_list_2nd).sum())/(n)\n",
    "prob_b = ((posterior_list_2nd > posterior_list_best).sum())/(n)\n",
    "prob_c = ((posterior_list_3rd > posterior_list_best).sum())/(n)\n",
    "prob_d = ((posterior_list_4th > posterior_list_best).sum())/(n)\n",
    "    \n",
    "ads_rvs = [cv_1, cv_2, cv_3, cv_4]\n",
    "print(ads_rvs)\n",
    "print('{} win:'.format(ads_rvs.index(first)), prob_a)\n",
    "print('{} win:'.format(ads_rvs.index(second)), prob_b)\n",
    "print('{} win:'.format(ads_rvs.index(third)), prob_c)\n",
    "print('{} win:'.format(ads_rvs.index(sorted_rvs[0])), prob_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianAB:\n",
    "    \n",
    "    def __init__(self, params=None, size=2):\n",
    "        \"\"\"\n",
    "            params are a list of Beta distribution's initial params. e.g. [[alpha of A, beta of A], [alpha of B, beta of B]]\n",
    "        \"\"\"\n",
    "        if params is None:\n",
    "            self.params = []\n",
    "            for _ in range(size):\n",
    "                self.params.append([1,1])\n",
    "        self.size = len(self.params)\n",
    "        self.data = []\n",
    "        for _ in range(size):\n",
    "            self.data.append([0,0])\n",
    "        print(\"the number of comparison: \", self.size)\n",
    "        self.sampling()\n",
    "        \n",
    "    def update(self, data, sampling=True):\n",
    "        \"\"\"\n",
    "         data are a list of pairs of impression and conversion. e.g. [[imp of A, conv of A], [imp of B, conv of B]]\n",
    "        \"\"\"\n",
    "        if self.size != len(data):\n",
    "            print(\"No match of the size.\")\n",
    "        \n",
    "        for p, current, new in zip(self.params, self.data, data):\n",
    "            imp = new[0]\n",
    "            conv = new[1]\n",
    "            current[0] += imp\n",
    "            current[1] += conv\n",
    "            p[0] += conv\n",
    "            p[1] += (imp - conv)\n",
    "        if sampling:\n",
    "            self.sampling()\n",
    "        \n",
    "        \n",
    "    def mean_ver(self):\n",
    "        \"\"\"\n",
    "            return [(mean of A, variance of A), (mean of B, variance of B), ...]\n",
    "        \"\"\"\n",
    "        return  [(posterior.mean(), posterior.var())for posterior in self.posterior_list]\n",
    "\n",
    "        \n",
    "        \n",
    "    def sampling(self, n_samples=50000):\n",
    "        print(\"num of samples: \", n_samples)\n",
    "        self.posterior_list = [beta(*p).rvs(n_samples) for p in self.params]\n",
    "\n",
    "\n",
    "        \n",
    "    def show_beta(self, title=\"\", save=False, labels=None):\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.title(\"Posterior distribution \"+ title)\n",
    "        \n",
    "        cmap = plt.get_cmap('jet')\n",
    "        color_list= []\n",
    "            \n",
    "        for i, posterior in enumerate(self.posterior_list):\n",
    "            color =cmap(0.25*(i+1))\n",
    "            color_list.append(color)\n",
    "            plt.hist(posterior, bins=100, histtype=\"stepfilled\", normed=True, color=color, alpha=0.5)\n",
    "        handles = [Rectangle((0,0),1,1,color=c, ec=\"k\", alpha=0.5) for c in color_list]\n",
    "        \n",
    "        if labels is None:\n",
    "            labels = [chr(65+i) for i in range(self.size)] # create A,B,...\n",
    "            \n",
    "\n",
    "        plt.legend(handles, labels)\n",
    "        if save:\n",
    "            plt.savefig(\"{}.png\".format(title))\n",
    "        plt.show()\n",
    "    \n",
    "    def diff_prob(self, index_high, index_low):\n",
    "        prob = (self.posterior_list[index_low] < self.posterior_list[index_high]).mean()\n",
    "        if prob < 0.5:\n",
    "            prob = 1 - prob\n",
    "        return prob\n",
    "    \n",
    "    def show_metrics(self):\n",
    "        print(self.data)\n",
    "        \n",
    "    def metrics(self, labels=None):\n",
    "        if labels is None:\n",
    "            labels = [chr(65+i) for i in range(self.size)] # create A,B,...\n",
    "        return pd.DataFrame(self.data, index=labels, columns=[\"Impressions\", \"Conversions\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of comparison:  2\n",
      "num of samples:  50000\n"
     ]
    }
   ],
   "source": [
    "abtest = BayesianAB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A \n",
      " Counts: 8000\n",
      " Conversions: 1600\n",
      "\n",
      "B \n",
      " Counts: 8000\n",
      " Conversions: 1500\n",
      "\n",
      "C \n",
      " Counts: 8000\n",
      " Conversions: 1580\n",
      "\n",
      "D \n",
      " Counts: 8000\n",
      " Conversions: 1480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imp_a = total\n",
    "imp_b = total\n",
    "imp_c = total\n",
    "imp_d = total\n",
    "\n",
    "conv_a = cv_a\n",
    "conv_b = cv_b\n",
    "conv_c = cv_c\n",
    "conv_d = cv_d\n",
    "print(\"A \\n Counts: {}\\n Conversions: {}\\n\".format(imp_a, conv_a))\n",
    "print(\"B \\n Counts: {}\\n Conversions: {}\\n\".format(imp_b, conv_b))\n",
    "print(\"C \\n Counts: {}\\n Conversions: {}\\n\".format(imp_c, conv_c))\n",
    "print(\"D \\n Counts: {}\\n Conversions: {}\\n\".format(imp_d, conv_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of comparison:  4\n",
      "num of samples:  50000\n",
      "num of samples:  50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:61: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "abtest = BayesianAB(size=4)\n",
    "abtest.update([[imp_a, conv_a], [imp_b, conv_b],[imp_c, conv_c],[imp_d, conv_d]])\n",
    "abtest.show_beta()\n",
    "#abtest.diff_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34645 0.00785\n"
     ]
    }
   ],
   "source": [
    "prob_c = ((posterior_list_c > posterior_list_a).sum())/(n)\n",
    "prob_d = ((posterior_list_d > posterior_list_a).sum())/(n)\n",
    "print(prob_c, prob_d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
